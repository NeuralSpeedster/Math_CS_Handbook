#import "../util.typ": *

== Линейные отображения

_Определение._ Пусть даны два векторных пространства $V$ и $W$. Отображение $cal(A): V -> W$ называется #underline([линейным]), если выполнены два условия:

+ $cal(x + y) = cal(x) + cal(y)$,  $forall x, y in V$.

+ $cal(lambda dot x) = lambda dot cal(x)$,  $forall lambda in RR, x in V$.

По умолчанию будем считать, что линейные отображения действуют между арифметическими пространствами, то есть  $cal(A): RR^n -> RR^m$.

=== Матрица линейного отображения

_Определение._ Матрицей $A$ линейного отображения $cal(A)$ называется матрица $m times n$, такая, что

 $ A^((j)) = cal(A) (e_i), forall j = 1, ..., n, $

 где $e_1,...e_n$ --- векторы стандартного базиса пространства $RR^n$.


- Линейное отображение $cal(A)$ однозначно определяется своей матрицей $A$.

  $square$ $forall x in RR^n: x = x_1 e_1 + ... + x_n e_n$. Но $cal(A) (x) = cal(A) (x_1 e_1) + ... + cal(A) (x_n e_n) = x_1 cal(A) (e_1) + ... + x_n cal(A) (e_n)$. $cal(A) (e_i)$ --- это столбцы нужной матрицы $A$. Обратно, если $x = x_1 A^((1)) + ... + x_n A^((n))$, то столбцы можно переписать как образы базисных векторов $RR^n$. $square.filled$

=== Алгебраические операции над линейными отображениями

+ Сложение. Пусть $cal(A), cal(B): RR^n -> RR^m$, тогда $forall x in RR^n$
  $
    cal(C) = cal(A) + cal(B) <=> cal(C) (x) = cal(A) (x) + cal(B) (x)
  $
  Здесь $cal(C)$ отображает $RR^n -> RR^m$.

+ Умножение на число. Пусть $cal(A): RR^n -> RR^m$ и $lambda in RR$, тогда $forall x in RR^n$:
  $
    cal(C) = lambda dot cal(A) <=> cal(C) (x) = lambda dot cal(A) (x)
  $
  Здесь $cal(C)$ отображает $RR^n -> RR^m$.

+ Умножение линейных отображений. Пусть $A: RR^n -> RR^m$ и $B: RR^p -> RR^n$. Тогда $cal(C): RR^p -> RR^m$:

  $
    cal(C) = cal(A) dot cal(B) <=> cal(C) (x) = cal(A) (cal(B) (x)), forall x in RR^p
  $

=== Алгебраические операции над матрицами


+ Сложение. Пусть $A, B$ - матрицы $m times n$. Для всех столбцов $forall j = 1, ..., n$:

  $ C = A +B <=> C^((j)) = A^((j)) + B^((j)) $

  Это следует из того, что для соответсвующих линейных отображений $ C^((j)) = cal(C) (e_j) = cal(A) (e_j) + cal(B) (e_j) = A^((j)) + B^((j)). $
  Или же
  #theorem([
  $
    c_(i j) = a_(i j) + b_(i j),
  $
  где $i=1, ..., m; j=1, ..., n.$
  ])

+ Умножение на число. Пусть $A$ - матрица $m times n$ и $lambda in RR$, тогда для всех столбцов $forall j = 1, ..., n$:
  $
    C = lambda dot A <=> C^((j)) = lambda dot A^((j))
  $
  Так как $cal(C) = lambda dot cal(A)$, то для всех $j = 1, ..., n$:
  $
    C = lambda dot A <=> cal(C) (e_j) = lambda dot cal(A) (e_j)
  $
  Или же
  #theorem([
  $
    C = lambda dot A <=> c_(i j) = lambda dot a_(i j),
  $
  где $i=1, ..., m; j=1, ..., n.$
  ])

+ Умножение матриц. Пусть матрица $A$ имеет размер $m times n$ и $B$ имеет размер $n times p$.
  $
    C = A dot B <=> C^((j)) = cal(C) (e_j), forall j = 1, ..., p
  $
  Так как $cal(C) = cal(A) dot cal(B)$, то для всех $j = 1, ..., p$:
  $
    cal(C) (e_j) = cal(A) (cal(B) (e_j)) = cal(A) (B^((j))) = cal(A) (b_(1 j) e_1 + ... + b_(n j) e_n) 
    = \ =
    b_(1 j) cal(A) (e_1) + ... + b_(n j) cal(A) (e_n)
    =
    b_(1 j) A^((1)) + ... + b_(n j) A^((n))
  $
  Получаем поэлементно:
  #theorem([

    $
      c_(i j) = sum_(k=1)^n a_(i k) dot b_(k j), \ forall i = 1, ..., m; j = 1, ..., p
    $
  ])

Несложно доказать, что эти операции корректно определены на множестве линейных отображений. 

=== Матричная запись линейного отображения

Пусть $cal(A): RR^n -> RR^m$ и $ x = vec(x_1, dots.v, x_n) in RR^n $
тогда
$
  y = vec(y_1, dots.v, y_n) in RR^m 
$

$
  y = cal(A) (x) = cal(A) (x_1 e_1 + ... + e_n x_n) = A^((1)) x_1 + ... + A^((n)) x_n
$

Для каждого элемента $y_i (i=1,...,m):$ 
$
  y_i = a_(i 1) x_1 + ... + a_(i n) x_n
$

Получаем *матричную запись* линейного отображения:
$
  y = A dot x
$

Система линейных уравнений с матрицей коэффициентов $A$ и столбцом свободных членов $b$ и столбцом неизвестных $x$ можно записать так:
$
  A dot x = b
$
=== Свойства матричных операций

+ Коммутативность сложения:
  $
    A + B = B + A
  $

+ Ассоциативность сложения:
  $
    (A + B) + C = A + (B + C)
  $

+ Нулевая матрица: 
  $
    O + A = A, forall A
  $

+ Ассоциативность умножения матрицы на число:
  $
    lambda dot (mu dot A) = (lambda dot mu) dot A
  $

+ Дистрибутивность умножения матриц на числа относительно сложения:
  + Чисел:
    $
      (lambda + mu) dot A = lambda dot A + mu dot A
    $
  + Матриц:
  $
    lambda dot (A + B) = lambda dot A + lambda dot B
  $

+ Умножение на нуль:
  $
    0 dot A = O
  $

+ Умножение на нулевую матрицу:
  $
    lambda dot O = O
  $

+ Умножение на единицу:
  $
    1 dot A = A
  $
+ Противоположная матрица:
  $
    A + (-A) = O
  $
  где $(-A) = (-1) dot A$.

  - Таким образом, множество всех матриц $m times n$ с операциями сложения и умножения на числа образует векторное пространство. Его элементы можно рассматривать как длинные векторы $m times n$.

+ Ассоциативность умножения матриц:
  $
    A dot (B dot C) = (A dot B) dot C
  $

+ Некоммутативность. Вообще говоря, 
  $
    A dot B != B dot A
  $

+ Смешанная ассоциативность:
  $
    (lambda dot A)  dot B = lambda dot (A dot B)
  $

+ Дистрибутивность матричного умножения относительно сложения:
  + Левая дистрибутивность:
    $
      A dot (B + C) = A dot B + A dot C
    $
  + Правая дистрибутивность:
  $
    (A + B) dot D = A dot D + B dot D
  $

=== Взаимодействие транспонирования и алгебраических операций над матрицами

_Прелоожение о транспонировании._
+ $(A + B)^T = A^T + B^T$

+ $(lambda dot A)^T = lambda dot A^T$
  
+ $(A dot B)^T = B^T dot A^T$

_Доказательство._
$square$ 

+ Пусть $C = A + B$. Тогда $forall i, j$:
  $
    c_(i j) ^ T = c_(j i) = a_(j i) + b_(j i) = a_(i j) ^ T + b_(i j) ^ T.
  $

+ Пусть $C = lambda dot A$, $forall i, j$:
  $
    c_(i j)^T = c_(j i) = lambda dot a_(j i) = lambda dot a_(i j)^T.
  $

+ Пусть $C = A dot B$, $forall i, j:$
  $
    c_(i j)^T = c_(j i) = sum_k a_(j k) dot b_(k i) = sum_k a_(k j)^T dot b_(i k)^T = sum_k b_(i k)^T dot a_(k j)^T
  $
  Отсюда $C^T = B^T dot A^T.$ $square.filled$


=== Ранг произведения двух матриц

#theorem([
  _Теорема._ Ранг произведения двух матриц не превосходит каждого из рангов сомножителей:
    $
      op("rk") (A dot B) <= min {op("rk") A, op("rk") B}
    $
])

_Доказательство._ $square$ Пусть $A in op("Mat")_(m, n)$, $B in op("Mat")_(n, p)$ $=> A dot B = C in op("Mat")_(m, p)$. $forall i, j$:

$
  c_(i j) = sum_(k=1)^n a_(i k) dot b_(k j)
$
$
  C_i = sum_(k=1)^n = a_(i k) dot B_k
$
Следовательно, система строк матрицы $C$ линейно выражается через систему векторов $B$. Значит ранг системы строк матрицы $C$ не превосходит ранга системы строк матрицы $B$.
Значит, $op("rk") C <= op("rk") B$. Аналогично, выражая систему стобцов ${C^((1)), ..., C^((p))}$ через столбцы матрицы $A$:
$
  C^((j)) = sum_(k=1)^n A^((k)) dot b_(k j)
$
Значит $op("rk") C <= op("rk") A$. $square.filled$

Аналогично можно показать, что 
$
  op("rk") (A + B) <= min{op("rk") A, op("rk") B}.
$

=== Тождественное отображение

_Определение._ Отображение $cal(E): RR^n -> RR^n$ называется тождественным,
если 
$
  cal(E) (x) = x, forall x in RR^n.
$ 

Матрица тождественного отображения:

$
  E = mat(
    1, 0, ..., 0;
    0, 1, ..., 0;
    ..., ..., ..., ...;
    0, 0, ..., 1
  )
$
Это так называемая _единичная матрица_ размера $n times n$.

Её элементы можно описать символом Кронекера:
$
  delta_(i j) = cases(
    1 \, "при" i = j,
    0 \, "при" i != j
  )
$

==== Основное свойство тождественного отображения и единичной матрицы
Основное свойство тождественного отображения $forall cal(A): RR^n -> RR^m$

$
  cal(A) dot cal(E) = cal(A)
$
Аналогично, $forall cal(B): RR^p -> RR^n:$
$ 
  cal(E) dot cal(B) = cal(B)
$

Из этого сразу следует основное свойство единичной матрицы:

$
  A dot E = A, forall A in op("Mat")_(m, n)
$
$
  E dot B = B, forall B in op("Mat")_(n, p)
$

=== Обратная матрица

_Определение._ Пусть $A in op("Mat")_n$. Матрица $B in op("Mat")_n$ называется обратной к матрице $A$, если 
$
  A dot B = B dot A = E.
$

Свойства обратной матрицы.

+ Если обратная матрица к данной существует, то она ровно одна.

  _Доказательство._ $square$ Пусть $B$ и $B'$ --- две обратные матрицы к $A$.
  $
    B dot A dot B' = (B dot A) dot B' = E dot B' = B'
  $
  $
    B dot A dot B' = B dot (A dot B') = B dot E = B
  $
  Поэтому $B = B'$. $square.filled$
  + Обратную матрицу к матрице $A$ обозначают $A^(-1)$.

+ Если матрица $A <-> cal(A): RR^n -> RR^n$, то $A^(-1) <-> cal(A)^(-1): RR^n -> RR^n$. Кроме того, обратное отображение тоже линейно.

+ Матрица $A$ обратима $<=>$ $cal(A)$ обратимо $<=> cal(A) "биективно"$.

#theorem([
_Предложение._ Если $A, B$ обратимы, то $A dot B$ обратимо и $(A dot B)^(-1) = B^(-1) dot A^(-1)$.

])

_Доказательство._ $square$ Рассмотрим $(A dot B) dot (B^(-1) dot A^(-1)) = A dot E dot A^(-1) = A dot A^(-1) = E$. Аналогично, в другом порядке получим при умножении $E$. Поэтому эти матрицы взаимно обратны.
$square.filled$

_Определение._ Квадратная матрица $A in op("Mat")_n$ называется _невырожденной_, если $op("rk") A = n$.

#theorem([
_Теорема._ Матрица $A in op("Mat")_n$ обратима тогда и только тогда, когда она невырождена.
])

_Доказательство._ $square$

+ $=>$. Пусть матрица $A$ обратима. Тогда $A dot A^(-1) = E$.
  Мы знаем, что ранг произвдения матриц не превосходит каждого из рангов сомножителей, значит
  $
    op("rk") (A dot A^(-1)) <= min {op("rk") A, op("rk") A^(-1)}
  $
  $
    n <= op("rk") A
  $
  Поэтому $op("rk") A = n$. И матрица $A$ невырождена.

+ $arrow.l.double$. Пусть $op("rk") A = n$. Тогда столбцы ${A^((1)), ..., A^((n))}$ линейно независимы. И они образуют базис в $RR^n$. Если бы эта система векторов была не максимальной, в ней было бы $> n$ векторов, но в любом пространстве $V$ с $dim V = n$ базис имеет ровно $n$ векторов.

  Тогда
  $
    forall y in RR^n space exists ! x_1, ..., x_n: y = sum_(i=1)^n x_i dot A^((i))
  $
  значит
  $
    forall y in RR^n space exists! x in RR^n: y = cal(A) (x),
  $
  где $cal(A): RR^n -> RR^n$ --- линейное отображение. Значит $A$ взаимно однозначно $=>$ обратимо $=>$ матрица этого отображения обратима.
$square.filled$

=== Алгоритм нахождения обратной матрицы

Пусть $A$ --- невыроженная матрица. Запишем расширенную матрицу $(A | E)$ и приведём к улучшенному ступенчатому виду матрицу $A$. Её улучшенный ступенчатый вид будет $E$. Утверждается, что матрица, которая получена с помощью элементарных преобразований на месте $E$ будет $A^(-1)$.


$
  (A | E) arrow.long_("элементарные\nпреобразования\nстрок") (E | A^(-1))
$
_Доказательство._ $square$ $X = A^(-1)$ является решением уравнения $A dot X = E$. Это уравнение равносильно системе:
$
  cases(
    A dot X^((j)) = E^((j)),
    forall j=1\,...\,n
  )
$
Каждое из уравнений на $X^((j))$ есть матричная запись СЛАУ с матрицей коэффициентов $A$ и свободным членом $E^((j))$. Решим её методом Гаусса:
$
  (A | E^((j))) arrow.long_("элементарные\nпреобразования\nстрок") (E | B^((j)))
$
Поэтому
$
  A dot X^((j)) = E^((j)) <=> E dot X^((j)) = B^((j)), space forall j=1,...,n.
$
$
  A dot X = E <=> E dot X = B
$
Единственное решение этого уравнения есть $X = B$, и поэтому $B = A^(-1)$.
$square.filled$

=== Элементарные матрицы

_Определение._ Элементарная матрица --- это матрица размера $n times n$, получаемая из $E$ с помощью одного элементарного преобразования строк или столбцов.

3 типа элементарных матриц.

+ Применяем ЭП I типа к $E$: прибавим к $i-й$ строке $j$-ю строку, умноженную на число $lambda$.

  $
  mat(
    1, 0, ..., 0;
    0, 1, ..., 0;
    ..., ..., ..., ...;
    0, 0, ..., 1) arrow.long^("ЭП I") U_(i j) (lambda) =

    mat(1, 0, ..., ..., ..., 0;
    0, ..., ..., ..., ..., 0;
    ..., ..., 1, lambda, ..., 0;
    ..., ..., ..., 1, ..., 0;
    0, 0, ..., ..., ..., 1

    ) <-i "-я строка"
  $

+ Применим к $E$ элементарное преобразование II типа: переставим $i$-ю и $j$-ю строки.
  $
    mat(
    1, 0, ..., 0;
    0, 1, ..., 0;
    ..., ..., ..., ...;
    0, 0, ..., 1) arrow.long^("ЭП II") U_(i j) = mat(1, 0, ..., ..., ..., 0;
    0, ..., ..., ..., ..., 0;
    ..., ..., 0, 1, ..., 0;
    ..., ..., 1, 0, ..., 0;
    0, 0, ..., ..., ..., 1

    ) <-i "-я строка"
  $

+ Применим к $E$ элементарное преобразование III типа: умножим $i$-ю строку на число $lambda != 0$.
$
  mat(
    1, 0, ..., 0;
    0, 1, ..., 0;
    ..., ..., ..., ...;
    0, 0, ..., 1) arrow.long^("ЭП III") U_i (lambda) = mat(1, 0, ..., ..., 0;
    0, ..., ..., ..., 0;
    ..., ..., lambda, ..., 0;
    0, 0, ..., ..., 1

    )
$

==== Основное свойство элементарных матриц

Пусть $A in op("Mat")_(m, n)$. Применим к $A$ одно элементарное преобразование строк и получим $A'$, тогда 

$
  A' = U dot A,
$
где $U$ --- элементарная матрица, соответствующая применённому элементарному преобразованию строк. 

Если же мы применим к $A$ одно элементарное преобразование столбцов и получим $A''$, то 

$
  A'' = A dot V,
$
где $V$ --- элементарная матрица, соответствующая применённому элементарному преобразованию столбцов.

_Доказательство._ $square$ Докажем последовательно утверждения про строки и про столбцы.

+ Для всех трёх типов элементарных преобразований, строки $A'_i$ являются линейными комбинациями строк $A_i$ с коэффициентами $lambda_(i k)$.
  $
    A_i = sum_(k=1)^m lambda_(i k) A_k
  $
  Так как элементарное преобразование то же самое, то
  $
    U_i = sum_(k=1)^m lambda_(i k) E_k = (lambda_(i 1), ..., lambda_(i m)),
  $
  где $E_k = (0, ..., 1_k, ..., 0)$
  $
    a'_(i j) = sum_(k=1)^m lambda_(i k) a_(k j) = (lambda_(i 1), ..., lambda_(i m)) dot vec(a_(1 j), dots.v, a_(m j)) = U_i dot A^((j))
  $
  Поэтому $A' = U dot A$.

+ Столбцы $A''^((j))$ выражаются через столбцы $A^((j))$.
  $
    A''^((j)) = sum_(k=1)^n mu_(k j) A^((k))
  $
  $
    V^((j)) = sum_(k=1)^n mu_(k j) E^((k)) = vec(mu_(1 j), dots.v, mu_(n j))
  $
  Поэтому
  $
    a''_(i j) = sum_(k=1)^n mu_(k j) a_(i k) = vec(a_(i 1), dots.v, a_(i n)) dot (mu_(1 j), ..., mu_(n j)) = A_i dot V^((j))
  $
  Следовательно, $A'' = A dot V$. $square.filled$


_Следствие._ Элементарные матрицы обратимы, причём обратная матрица будет элементарной, полученной обратным элементарным преобразованием.

_Доказательство._ $square$ Пусть $E -> U$ --- элементарная матрица, полученная преобразованиями строк. Тогда можно получить $U -> E$ обратным преобразованием. Но если применить это же обратное преобразование к $E$, то получим некую матрицу $V$.
$
  U <-> E <-> V
$
Из основного свойства элементарных матриц:
$
  E = V dot U
$
(получили матрицу $E$ из матрицы $U$ с помощью обратного элементарного преобразования $V$).

С другой стороны, можно получить $E$ из матрицы $V$ с помощью обратного к обратному ЭП, то есть умножением на $U$:
$
  E = U dot V
$
Поэтому $V$ обратна к $U$. Аналогично доказывается утверждение для столбцов.
$square.filled$

==== Разложение невырожденной матрицы в произведение элементарных матриц

#theorem([
_Теорема._ Всякая невырожденная матрица раскладывается в произведение элементарных матриц.
])

_Доказательство._ $square$ Так как матрица $A$ невырожденная, то с помощью элементарных преобразований строк можно привести её к единичной матрице $E$. По основному свойству элементарных матриц это означает, что существует последовательность элементарных матриц $U_1, U_2, ..., U_k$, таких что

$
  U_k dot U_(k-1) dot ... dot U_1 dot A = E
$
где $U_i$ получается с помощью $i$-го элементарного преобразования строк. 

Так как для каждой из $U_i$ существует обратная элементарная матрица $U_i^(-1)$, то умножив это равенство последовательно слева на обратные матрицы, получим

$
  A = U_1^(-1) dot U_2^(-1) dot ... dot U_k^(-1) dot E = U_1^(-1) dot U_2^(-1) dot ... dot U_k^(-1)
$
Мы получили разложение $A$ в произведение элементарных матриц, причём это матрицы тех преобразований, которые нужно получить, чтобы из единичной матрицы получить $A$.
$square.filled$